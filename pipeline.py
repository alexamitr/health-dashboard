# pipeline.py
# Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ­Ï‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± preprocess, Ï†ÏŒÏÏ„Ï‰Î¼Î± Î¼Î¿Î½Ï„Î­Î»Ï‰Î½, inference (Î­Î½Î±/Ï€Î¿Î»Î»Î¬),
# ÏƒÏÎ½Î¸ÎµÏƒÎ· alerts/recs, timelines ÎºÎ±Î¹ debouncing.

from __future__ import annotations
from typing import List, Dict, Any, Tuple, Optional

import numpy as np
import pandas as pd
import joblib

# ==============================
# 1) PREPROCESS (Î¯Î´Î¹Î¿ Î¼Îµ training)
# ==============================

def preprocess_for_inference(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    Î¦Ï„Î¹Î¬Ï‡Î½Ï‰ Î‘ÎšÎ¡Î™Î’Î©Î£ Ï„Î± features Ï€Î¿Ï… ÎµÎ¯Ï‡ÎµÏ‚ ÏƒÏ„Î¿ training:
    - hour, minute, sin_time, cos_time (Î±Ï€ÏŒ sec_of_day Î® timestamp)
    - rolling mean/std 5' (300 Î´ÎµÎ¯Î³Î¼Î±Ï„Î±, 1Hz)
    - lags 60s & 300s Î³Î¹Î± HR/EDA/TEMP
    - drops 60s: HR_drop, TEMP_drop
    - interactions: HRxTemp (=HR*Temperature), EDAxHum (=EDA*Humidity)
    - Ï€ÎµÏ„Î¬Ï‰ Î³ÏÎ±Î¼Î¼Î­Ï‚ Î¼Îµ NaN Î»ÏŒÎ³Ï‰ rolling/lag/diff (Î¯Î´Î¹Î± Î»Î¿Î³Î¹ÎºÎ® Î¼Îµ training)
    """
    df = df_raw.copy()

    # ÎˆÎ»ÎµÎ³Î¾Îµ ÏŒÏ„Î¹ Î­Ï‡ÎµÎ¹Ï‚ Ï‡ÏÏŒÎ½Î¿ + Î²Î±ÏƒÎ¹ÎºÎ¬ ÏƒÎ®Î¼Î±Ï„Î±
    need_time = ('sec_of_day' in df.columns) or ('timestamp' in df.columns)
    if not need_time:
        raise ValueError("Î§ÏÎµÎ¹Î¬Î¶Î¿Î¼Î±Î¹ 'timestamp' Î® 'sec_of_day'.")
    for col in ['HR', 'EDA', 'TEMP', 'Temperature', 'Humidity']:
        if col not in df.columns:
            raise ValueError(f"Î›ÎµÎ¯Ï€ÎµÎ¹ ÏƒÏ„Î®Î»Î·: {col}")

    # Î‘Î½ Î´ÎµÎ½ Î­Ï‡ÎµÎ¹Ï‚ sec_of_day, Ï„Î¿ Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶Ï‰ Î±Ï€ÏŒ timestamp
    if 'sec_of_day' not in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        df['sec_of_day'] = (
            df['timestamp'].dt.hour * 3600
            + df['timestamp'].dt.minute * 60
            + df['timestamp'].dt.second
        )

    # ÎšÏ…ÎºÎ»Î¹ÎºÎ¬ Ï‡ÏÎ¿Î½Î¹ÎºÎ¬ features
    df['hour']     = df['sec_of_day'] // 3600
    df['minute']   = (df['sec_of_day'] % 3600) // 60
    df['sin_time'] = np.sin(2 * np.pi * df['sec_of_day'] / 86400)
    df['cos_time'] = np.cos(2 * np.pi * df['sec_of_day'] / 86400)

    # Rolling 5' (300 Î´ÎµÎ¯Î³Î¼Î±Ï„Î±, 1Hz)
    for var in ['HR', 'EDA', 'TEMP']:
        df[f'{var}_rollmean'] = df[var].rolling(window=300, min_periods=1).mean()
        df[f'{var}_rollstd']  = df[var].rolling(window=300, min_periods=1).std()

    # Lags 60s & 300s
    for lag in [60, 300]:
        for var in ['HR', 'EDA', 'TEMP']:
            df[f'{var}_lag{lag}'] = df[var].shift(lag)

    # Drops 60s (Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎ±Î½ ÏƒÎµ ÎºÎ¬Ï€Î¿Î¹Î± Î¼Î¿Î½Ï„Î­Î»Î± ÏƒÎ¿Ï…)
    df['HR_drop']   = df['HR'].diff(60)
    df['TEMP_drop'] = df['TEMP'].diff(60)

    # Interactions
    df['HRxTemp'] = df['HR'] * df['Temperature']
    df['EDAxHum'] = df['EDA'] * df['Humidity']

    # Î ÎµÏ„Î¬Ï‰ Î³ÏÎ±Î¼Î¼Î­Ï‚ Î¼Îµ NaN Î»ÏŒÎ³Ï‰ rolling/lag/diff (Î¯Î´Î¹Î± Î»Î¿Î³Î¹ÎºÎ® Î¼Îµ training)
    lag_roll_cols = [c for c in df.columns if ('_lag' in c) or ('_roll' in c)]
    lag_roll_cols += ['HR_drop', 'TEMP_drop']
    df = df.dropna(subset=lag_roll_cols).reset_index(drop=True)

    return df


# ==========================================
# 2) LOAD MODEL + ALIGN FEATURES (helpers)
# ==========================================

def load_model_and_features(model_path: str, features_path: str):
    """
    Î¦Î¿ÏÏ„ÏÎ½Ï‰ Ï„Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ (.pkl) ÎºÎ±Î¹ Ï„Î· Î»Î¯ÏƒÏ„Î± Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½ features (.pkl).
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Ï‰ (model, feature_list).
    """
    model = joblib.load(model_path)
    feature_list = joblib.load(features_path)
    if not isinstance(feature_list, (list, tuple)):
        raise TypeError("Î¤Î¿ features_pkl Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î»Î¯ÏƒÏ„Î±/tuple.")
    return model, list(feature_list)

def align_features(df_engineered: pd.DataFrame, feature_list: List[str]) -> pd.DataFrame:
    """
    Î•Ï…Î¸Ï…Î³ÏÎ±Î¼Î¼Î¯Î¶Ï‰ Ï„Î± engineered Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Îµ Ï„Î± features Ï€Î¿Ï… Ï€ÎµÏÎ¹Î¼Î­Î½ÎµÎ¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿:
    - Î‘Î½ Î»ÎµÎ¯Ï€ÎµÎ¹ ÎºÎ¬Ï€Î¿Î¹Î± ÏƒÏ„Î®Î»Î·, Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Ï Î¼Îµ 0.0 (Î±ÏƒÏ†Î±Î»Î®Ï‚ default).
    - ÎšÏÎ±Ï„Ï ÎœÎŸÎÎŸ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ Ï„Î¿Ï… feature_list ÎºÎ±Î¹ Î¼Îµ Ï„Î·Î½ Î¯Î´Î¹Î± ÏƒÎµÎ¹ÏÎ¬.
    - ÎœÎµÏ„Î±Ï„ÏÎ­Ï€Ï‰ ÏƒÎµ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¿ÏÏ‚ Ï„ÏÏ€Î¿Ï…Ï‚ ÏŒÏ€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹.
    """
    X = df_engineered.copy()

    for col in feature_list:
        if col not in X.columns:
            X[col] = 0.0

    X = X[feature_list]

    for c in X.columns:
        if X[c].dtype == 'bool':
            X[c] = X[c].astype(int)
        elif not pd.api.types.is_numeric_dtype(X[c]):
            X[c] = pd.to_numeric(X[c], errors='coerce').fillna(0.0)

    return X


# ==========================================
# 3) INFERENCE (Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î¿ & Ï€Î¿Î»Î»Î¬ Î¼Î¿Î½Ï„Î­Î»Î±)
# ==========================================

def predict_single_model(
    df_engineered: pd.DataFrame,
    model_path: str,
    features_path: str,
    threshold: float = 0.5,
    return_frame: bool = True
) -> Tuple[np.ndarray, Optional[np.ndarray], Optional[pd.DataFrame]]:
    """
    ÎšÎ¬Î½Ï‰ inference Î³Î¹Î± Î•ÎÎ‘ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€Î¬Î½Ï‰ ÏƒÎµ Î—Î”Î— Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± (df_engineered).
    - Î¦Î¿ÏÏ„ÏÎ½Ï‰ Î¼Î¿Î½Ï„Î­Î»Î¿ + feature list, ÎµÏ…Î¸Ï…Î³ÏÎ±Î¼Î¼Î¯Î¶Ï‰ ÏƒÏ„Î®Î»ÎµÏ‚.
    - Î‘Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ predict_proba â†’ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Ï‰ proba + pred Î¼Îµ threshold.
    - Î‘Î»Î»Î¹ÏÏ‚ â†’ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Ï‰ Î¼ÏŒÎ½Î¿ pred.
    """
    model, feature_list = load_model_and_features(model_path, features_path)
    X = align_features(df_engineered, feature_list)

    if hasattr(model, "predict_proba"):
        y_proba = model.predict_proba(X)[:, 1]
        y_pred  = (y_proba >= threshold).astype(int)
    else:
        y_proba = None
        y_pred  = model.predict(X).astype(int)

    out_df = None
    if return_frame:
        out_df = pd.DataFrame(index=df_engineered.index)
        if y_proba is not None:
            out_df["prob"] = y_proba
        out_df["pred"] = y_pred

    return y_pred, y_proba, out_df


def predict_all_models(
    df_engineered: pd.DataFrame,
    model_specs: List[Dict[str, Any]],
    default_threshold: float = 0.5,
    keep_proba: bool = True,
    verbose: bool = True
) -> Tuple[pd.DataFrame, Dict[str, Dict[str, Any]]]:
    """
    Î¤ÏÎ­Ï‡Ï‰ Î ÎŸÎ›Î›Î‘ Î¼Î¿Î½Ï„Î­Î»Î± (NOW + FUTURE) Ï€Î¬Î½Ï‰ ÏƒÎµ Î—Î”Î— Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±.
    - Î ÎµÏÎ¹Î¼Î­Î½Ï‰ model_specs Î¼Îµ ÎºÎ»ÎµÎ¹Î´Î¹Î¬: name, model_path, features_path, (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ threshold, kind)
    - Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Ï‰ DataFrame Î¼Îµ <name>_pred (+ <name>_prob Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹) ÎºÎ±Î¹ meta dict.
    """
    out_df = pd.DataFrame(index=df_engineered.index)
    meta: Dict[str, Dict[str, Any]] = {}

    for spec in model_specs:
        name = spec["name"]
        model_path = spec["model_path"]
        features_path = spec["features_path"]
        threshold = spec.get("threshold", default_threshold)
        kind = spec.get("kind", "")

        if verbose:
            print(f"ğŸ”® Î¤ÏÎ­Ï‡Ï‰: {name} (thr={threshold})")

        try:
            y_pred, y_proba, _ = predict_single_model(
                df_engineered=df_engineered,
                model_path=model_path,
                features_path=features_path,
                threshold=threshold,
                return_frame=False
            )

            out_df[f"{name}_pred"] = y_pred.astype(int)
            if keep_proba and (y_proba is not None):
                out_df[f"{name}_prob"] = y_proba.astype(float)

            meta[name] = {
                "kind": kind,
                "threshold": threshold,
                "model_path": model_path,
                "features_path": features_path,
                "has_proba": y_proba is not None,
                "n_positives": int(np.sum(y_pred)),
                "positives_pct": float(np.mean(y_pred))
            }

        except Exception as e:
            if verbose:
                print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ '{name}': {e}")
            out_df[f"{name}_pred"] = 0
            meta[name] = {
                "kind": kind,
                "threshold": threshold,
                "model_path": model_path,
                "features_path": features_path,
                "has_proba": False,
                "error": str(e)
            }

    return out_df, meta


# ==========================================
# 4) ALERTS & RECOMMENDATIONS
# ==========================================

# Î£Î¿Î²Î±ÏÏŒÏ„Î·Ï„ÎµÏ‚ Î±Î½Î¬ event (Ï€ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÎ¶ÎµÎ¹Ï‚ Î±Î½ Î¸ÎµÏ‚)
EVENT_SEVERITY = {
    "stress":       2,  # MED
    "fatigue":      2,  # MED
    "dehydration":  2,  # MED
    "envrisk":      2,  # MED
    "arrhythmia":   3,  # HIGH
    "hypothermia":  3,  # HIGH
    "syncope":      4,  # CRITICAL (Î±Î½ Ï„Î¿ Ï€ÏÎ¿ÏƒÎ¸Î­ÏƒÎµÎ¹Ï‚)
}
SEVERITY_LABEL = {0: "NONE", 1: "LOW", 2: "MED", 3: "HIGH", 4: "CRITICAL"}

# Î£Ï…ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ (NOW/FUTURE)
EVENT_RECS_NOW = {
    "stress":      "Î‘Î½Î±Ï€Î½Î¿Î­Ï‚/Î´Î¹Î¬Î»ÎµÎ¹Î¼Î¼Î±, ÎµÎ½Ï…Î´Î¬Ï„Ï‰ÏƒÎ·, Ï‡Î±Î¼Î®Î»Ï‰ÏƒÎµ ÏÏ…Î¸Î¼ÏŒ.",
    "fatigue":     "Î£ÏÎ½Ï„Î¿Î¼Î· Î±Î½Î¬Ï€Î±Ï…ÏƒÎ·, Î±Î½Î±ÎºÎ±Ï„Î±Î½Î¿Î¼Î® Ï†ÏŒÏÏ„Î¿Ï…, ÎºÎ±Ï†ÎµÎÎ½Î· Î±Î½ ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÏ„Î±Î¹.",
    "dehydration": "Î•Î½Ï…Î´Î¬Ï„Ï‰ÏƒÎ·, Î·Î»ÎµÎºÏ„ÏÎ¿Î»ÏÏ„ÎµÏ‚, Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· ÏƒÏ…Î³Ï‡ÏÏƒÎµÏ‰Î½.",
    "envrisk":     "Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î­ÎºÎ¸ÎµÏƒÎ·Ï‚, ÎºÎ±Ï„Î±Ï†ÏÎ³Î¹Î¿, Ï„Î®ÏÎ·ÏƒÎ· Ï€ÏÏ‰Ï„Î¿ÎºÏŒÎ»Î»Î¿Ï….",
    "arrhythmia":  "Î‘ÎºÎ¹Î½Î·ÏƒÎ¯Î±, ÎºÎ±Ï„Î±Î³ÏÎ±Ï†Î® (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹), ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î¹Î±Ï„ÏÎ¹ÎºÎ® Î¿Î¼Î¬Î´Î±.",
    "hypothermia": "Î˜Î­ÏÎ¼Î±Î½ÏƒÎ·, Î¾Î·ÏÎ¬ ÏÎ¿ÏÏ‡Î±, Î¶ÎµÏƒÏ„Î¬ Ï…Î³ÏÎ¬ ÏŒÏ€Î¿Ï… ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÏ„Î±Î¹.",
    "syncope":     "ÎšÎ¬Î¸Î¹ÏƒÎµ/ÏÏ€Ï„Î¹Î± Î¸Î­ÏƒÎ·, Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î¶Ï‰Ï„Î¹ÎºÏÎ½, Î¬Î¼ÎµÏƒÎ· Î¹Î±Ï„ÏÎ¹ÎºÎ® ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ·.",
}
EVENT_RECS_FUTURE = {
    "stress":      "Î ÏÏŒÎ»Î·ÏˆÎ·: Î®Ï€Î¹Î± Î±Î½Î±Ï€Î½Î¿Î®, ÏÏÎ¸Î¼Î¹ÏƒÎµ ÏÏ…Î¸Î¼ÏŒ, Ï€ÏÎ¿Î»Î·Ï€Ï„Î¹ÎºÎ® ÎµÎ½Ï…Î´Î¬Ï„Ï‰ÏƒÎ·.",
    "fatigue":     "Î ÏÏŒÎ»Î·ÏˆÎ·: Î¼Î¹ÎºÏÏŒ Î´Î¹Î¬Î»ÎµÎ¹Î¼Î¼Î±/rotation, Ï€ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± ÎºÎ±Ï†ÎµÎÎ½Î·Ï‚.",
    "dehydration": "Î ÏÏŒÎ»Î·ÏˆÎ·: Ï…Î³ÏÎ¬/Î·Î»ÎµÎºÏ„ÏÎ¿Î»ÏÏ„ÎµÏ‚ Ï€ÏÎ¹Î½ Ï„Î± ÏƒÏ…Î¼Ï€Ï„ÏÎ¼Î±Ï„Î±.",
    "envrisk":     "Î ÏÏŒÎ»Î·ÏˆÎ·: ÏƒÎºÎ¹Î¬/ÎºÎ±Ï„Î±Ï†ÏÎ³Î¹Î¿, ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎµ Ï„Î·Î½ Î¿Î¼Î¬Î´Î±.",
    "arrhythmia":  "Î ÏÏŒÎ»Î·ÏˆÎ·: Î¼ÎµÎ¯Ï‰ÏƒÎµ Î­Î½Ï„Î¿Î½Î· Î´ÏÎ±ÏƒÏ„Î·ÏÎ¹ÏŒÏ„Î·Ï„Î±, ÎµÎ¾Î¿Ï€Î»Î¹ÏƒÎ¼ÏŒÏ‚ standby.",
    "hypothermia": "Î ÏÏŒÎ»Î·ÏˆÎ·: Ï€ÏÏŒÏƒÎ¸ÎµÏ„Î· Î¼ÏŒÎ½Ï‰ÏƒÎ·/ÏÎ¿ÏÏ‡Î±, Î¸ÎµÏÎ¼Î±Î½Ï„Î¹ÎºÎ¬ Î¼Î­Ï„ÏÎ±.",
    "syncope":     "Î ÏÏŒÎ»Î·ÏˆÎ·: ÏƒÏ„Î®ÏÎ¹Î¾Î·, Î±Ï€ÏŒÏ†Ï…Î³Îµ Î±Ï€ÏŒÏ„Î¿Î¼ÎµÏ‚ Î¼ÎµÏ„Î±Î²Î¬ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¬ÏƒÎ·Ï‚.",
}

def _event_key_from_name(model_name: str) -> str:
    """
    Î•Î¾Î¬Î³Ï‰ Î²Î±ÏƒÎ¹ÎºÏŒ event Î±Ï€ÏŒ Ï„Î¿ 'name' Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… (Ï€.Ï‡. 'stress_future' â†’ 'stress').
    """
    for key in EVENT_SEVERITY.keys():
        if model_name.startswith(key):
            return key
    return "unknown"

def compose_alerts_and_recs(pred_df: pd.DataFrame, model_specs: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    Î£Ï…Î½Î¸Î­Ï„Ï‰ Î±Î½Î¬ Î³ÏÎ±Î¼Î¼Î®:
    - alert_score: Î¼Î­Î³Î¹ÏƒÏ„Î· ÏƒÎ¿Î²Î±ÏÏŒÏ„Î·Ï„Î± Î±Ï€ÏŒ Ï„Î± ÎµÎ½ÎµÏÎ³Î¬ events
    - alert_level: ÎµÏ„Î¹ÎºÎ­Ï„Î± ÏƒÎ¿Î²Î±ÏÏŒÏ„Î·Ï„Î±Ï‚
    - recommendations: ÎµÎ½Î¹Î±Î¯Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î¼Îµ ÏƒÏ…ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ (NOW/FUTURE)
    Î’Î±ÏƒÎ¯Î¶Î¿Î¼Î±Î¹ ÏƒÏ„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ <name>_pred (+ Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ <name>_prob) ÎºÎ±Î¹ ÏƒÏ„Î¿ kind (NOW/FUTURE).
    """
    out = pred_df.copy()
    name_to_kind = {spec["name"]: spec.get("kind", "") for spec in model_specs}

    alert_scores: List[int] = []
    alert_levels: List[str] = []
    rec_texts: List[str] = []

    for _, row in out.iterrows():
        active_sev = 0
        recs: List[str] = []

        for spec in model_specs:
            name = spec["name"]
            kind = name_to_kind.get(name, "")
            pred_col = f"{name}_pred"
            if pred_col in row.index and int(row[pred_col]) == 1:
                ev = _event_key_from_name(name)
                sev = EVENT_SEVERITY.get(ev, 1)
                active_sev = max(active_sev, sev)

                # Î•Ï€Î¹Î»Î¿Î³Î® ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… ÏƒÏ…ÏƒÏ„Î¬ÏƒÎµÏ‰Î½
                tip = EVENT_RECS_NOW.get(ev, "") if kind == "NOW" else EVENT_RECS_FUTURE.get(ev, "")
                tag = "Î¤Î©Î¡Î‘" if kind == "NOW" else "Î Î¡ÎŸÎ’Î›Î•Î¨Î— 5â€²"
                if tip:
                    recs.append(f"[{tag} â€¢ {ev}] {tip}")

        alert_scores.append(active_sev)
        alert_levels.append(SEVERITY_LABEL.get(active_sev, "NONE"))
        rec_texts.append(" | ".join(recs) if recs else "ÎšÎ±Î½Î¿Î½Î¹ÎºÎ® Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·.")

    out["alert_score"] = alert_scores
    out["alert_level"] = alert_levels
    out["recommendations"] = rec_texts
    return out


# ==========================================
# 5) TIMELINE (rolling) & DEBOUNCING
# ==========================================

def make_alert_timeline(
    pred_df: pd.DataFrame,
    model_name: str,
    timestamps: Optional[pd.Series] = None,
    window_seconds: int = 300
) -> pd.DataFrame:
    """
    Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶Ï‰ ÎºÏ…Î»Î¹ÏŒÎ¼ÎµÎ½Î¿ Î¬Î¸ÏÎ¿Î¹ÏƒÎ¼Î± alerts Î³Î¹Î± Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î¿ (Ï€.Ï‡. 'stress_future') ÏƒÎµ Ï€Î±ÏÎ¬Î¸Ï…ÏÎ¿ N Î´ÎµÏ…Ï„ÎµÏÎ¿Î»Î­Ï€Ï„Ï‰Î½.
    - ÎœÎµ timestamps: resample ÏƒÎµ 1s ÎºÎ±Î¹ rolling 'Ns' (Ï€Î¹Î¿ ÏƒÏ‰ÏƒÏ„Î® Ï‡ÏÎ¿Î½Î¿ÎºÎ»Î¯Î¼Î±ÎºÎ±).
    - Î§Ï‰ÏÎ¯Ï‚ timestamps: Ï…Ï€Î¿Î¸Î­Ï„Ï‰ 1Hz ÎºÎ±Î¹ rolling Î¼Îµ window=N Î´ÎµÎ¯Î³Î¼Î±Ï„Î±.
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Ï‰:
      - Î¼Îµ timestamps: ['ts', '<name>_pred', 'rolling_count']
      - Ï‡Ï‰ÏÎ¯Ï‚ timestamps: ['<name>_pred', 'rolling_count']
    """
    pred_col = f"{model_name}_pred"
    if pred_col not in pred_df.columns:
        raise KeyError(f"Î”ÎµÎ½ Î²ÏÎ®ÎºÎ± ÏƒÏ„Î®Î»Î· '{pred_col}' ÏƒÏ„Î¿ pred_df.")

    s = pred_df[pred_col].astype(int)

    if timestamps is not None:
        if len(timestamps) != len(s):
            raise ValueError("Î¤Î¿ Î¼Î®ÎºÎ¿Ï‚ Ï„Î¿Ï… timestamps Î´ÎµÎ½ Ï„Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹ Î¼Îµ Ï„Î¿ pred_df.")
        ts = pd.to_datetime(timestamps, errors='coerce')

        tmp = pd.DataFrame({pred_col: s.values}, index=ts).sort_index()

        # Resample ÏƒÎµ 1s (Ï€ÎµÎ¶ÏŒ 's' Î³Î¹Î± Î±Ï€Î¿Ï†Ï…Î³Î® FutureWarning)
        tmp_1s = tmp.resample("1s").max().fillna(0).astype(int)

        # Rolling Î¬Î¸ÏÎ¿Î¹ÏƒÎ¼Î± Î¼Îµ Ï€Î±ÏÎ¬Î¸Ï…ÏÎ¿ Ï‡ÏÏŒÎ½Î¿Ï…
        window = pd.Timedelta(seconds=window_seconds)
        roll_df = tmp_1s.rolling(window, min_periods=1).sum()

        out = pd.DataFrame({
            "ts": tmp_1s.index,
            pred_col: tmp_1s[pred_col].values,
            "rolling_count": roll_df[pred_col].values
        })
        return out[["ts", pred_col, "rolling_count"]]

    # Î§Ï‰ÏÎ¯Ï‚ timestamps â†’ 1Hz index
    rolling_count = s.rolling(window=window_seconds, min_periods=1).sum()
    out = pd.DataFrame({pred_col: s.values, "rolling_count": rolling_count.values})
    return out


def apply_alert_rule(
    timeline_df: pd.DataFrame,
    model_name: str,
    count_threshold: int = 3,
    min_persist_seconds: int = 5
) -> pd.DataFrame:
    """
    Î•Ï†Î±ÏÎ¼ÏŒÎ¶Ï‰ ÎºÎ±Î½ÏŒÎ½Î± ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ (debouncing) ÏƒÏ„Î¿ rolling timeline:
    - active_raw: 1 ÏŒÏ„Î±Î½ rolling_count â‰¥ count_threshold
    - active_debounced: 1 ÏŒÏ„Î±Î½ ÎºÏÎ±Ï„Î¬ Ï„Î¿Ï…Î». min_persist_seconds ÏƒÏ…Î½ÎµÏ‡ÏŒÎ¼ÎµÎ½Î±
    - edge_on: 1 ÏƒÏ„Î¿ Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î¿ Ï€Î¿Ï… Â«Î±Î½Î¬Î²ÎµÎ¹Â» Ï„Î¿ debounced alert (rising edge)
    """
    pred_col = f"{model_name}_pred"
    if "rolling_count" not in timeline_df.columns:
        raise KeyError("Î›ÎµÎ¯Ï€ÎµÎ¹ Î· ÏƒÏ„Î®Î»Î· 'rolling_count' ÏƒÏ„Î¿ timeline_df.")
    if pred_col not in timeline_df.columns:
        raise KeyError(f"Î›ÎµÎ¯Ï€ÎµÎ¹ Î· ÏƒÏ„Î®Î»Î· '{pred_col}' ÏƒÏ„Î¿ timeline_df.")

    df = timeline_df.copy()
    df["active_raw"] = (df["rolling_count"] >= count_threshold).astype(int)

    run_sum = df["active_raw"].rolling(window=min_persist_seconds, min_periods=1).sum()
    df["active_debounced"] = (run_sum >= min_persist_seconds).astype(int)

    prev = df["active_debounced"].shift(1, fill_value=0)
    df["edge_on"] = ((df["active_debounced"] == 1) & (prev == 0)).astype(int)

    keep_cols: List[str] = []
    if "ts" in df.columns:
        keep_cols.append("ts")
    keep_cols += [pred_col, "rolling_count", "active_raw", "active_debounced", "edge_on"]
    return df[keep_cols]


# ==========================================
# 6) (Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ) Î£Ï…Î½Î¿Ï€Ï„Î¹ÎºÎ¬ Î³Î¹Î± dashboard
# ==========================================

def summarize_for_dashboard(
    pred_df: pd.DataFrame,
    alerts_df: pd.DataFrame,
    model_specs: List[Dict[str, Any]],
    top_n: int = 10
) -> Dict[str, Any]:
    """
    Î•Ï„Î¿Î¹Î¼Î¬Î¶Ï‰ ÏƒÏ…Î½Î¿Ï€Ï„Î¹ÎºÎ¬ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Î³Î¹Î± dashboard:
    - counts & rates Î±Î½Î¬ event ÎºÎ±Î¹ Î±Î½Î¬ Ï„ÏÏ€Î¿ (NOW/FUTURE)
    - ÏƒÏÎ½Î¿ÏˆÎ· Î±Î½Î¬ alert_level
    - Ï„Î± Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± N ÎµÎ½ÎµÏÎ³Î¬ alerts (Î¼Îµ timestamp Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹)
    """
    name_to_kind = {spec["name"]: spec.get("kind", "") for spec in model_specs}

    # events summary
    events_summary: Dict[str, Dict[str, Dict[str, float]]] = {}
    for spec in model_specs:
        name = spec["name"]
        kind = name_to_kind.get(name, "")
        ev   = _event_key_from_name(name)
        col  = f"{name}_pred"
        if col in pred_df.columns:
            cnt = int(pred_df[col].sum())
            rate = float(pred_df[col].mean())
            events_summary.setdefault(ev, {})
            events_summary[ev][kind] = {"count": cnt, "rate": rate}

    # levels summary
    level_counts = alerts_df["alert_level"].value_counts(dropna=False).to_dict()

    # recent active
    active = alerts_df[alerts_df["alert_score"] > 0].copy()
    if "timestamp" in active.columns:
        active = active.sort_values("timestamp")
        recent_cols = ["timestamp", "alert_level", "recommendations"]
    else:
        recent_cols = ["alert_level", "recommendations"]
    recent = active.tail(top_n)[recent_cols]

    return {"events": events_summary, "levels": level_counts, "recent": recent}
